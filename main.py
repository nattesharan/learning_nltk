from nltk.book import *
text1.concordance('name')
text1.similar('love')
text2.common_contexts(['monstrous','very'])
# text1.dispersion_plot(['love'])
lexical_richness = float(len(set(text5)))/float(len(text5))
print('Lexical Richness ----> '+str(lexical_richness))
c = text5.count('lol')
print(c)
perc_word = 100 * float(c)/len(text5)
print('Perc of lol is '+str(perc_word))
